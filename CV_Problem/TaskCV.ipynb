{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tso2BzPdxnhM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wn1qiU-nxzf4"
   },
   "outputs": [],
   "source": [
    "with open(\"test_image.pkl\", \"rb\") as f:\n",
    "    testImages = pickle.load(f)\n",
    "with open(\"train_image.pkl\", \"rb\") as f:\n",
    "    trainImages = pickle.load(f)\n",
    "with open(\"train_label.pkl\", \"rb\") as f:\n",
    "    trainLabels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4POLTaZeOLjg"
   },
   "outputs": [],
   "source": [
    "# Replacing class label 6 with 1\n",
    "for i in range(8000):\n",
    "    if(trainLabels[i]==6): \n",
    "        trainLabels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2Mzpe7C1TYp"
   },
   "outputs": [],
   "source": [
    "trainImages = (np.asarray(trainImages)).reshape(-1,1,28,28)\n",
    "testImages = (np.asarray(testImages)).reshape(-1,1,28,28)\n",
    "\n",
    "trainImages = (torch.from_numpy(trainImages)).float()\n",
    "trainLabels = torch.from_numpy(np.asarray(trainLabels))\n",
    "testImages = (torch.from_numpy(np.asarray(testImages))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbb5AaT2Jsp-"
   },
   "outputs": [],
   "source": [
    "BatchSize = 64\n",
    "\n",
    "trainset = torch.utils.data.TensorDataset(trainImages, trainLabels)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJbgFAB4NHVH"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(6400,512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "n5PE7IGkTyOm",
    "outputId": "c75e6516-a9c1-493a-ab1b-0862caeb4280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=6400, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ApmS5dA8T1R7",
    "outputId": "115cf69d-6d71-432a-ba2d-f5848d2ece12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU unavailable !\n"
     ]
    }
   ],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available !')   \n",
    "    net = net.cuda()\n",
    "else:\n",
    "    print('GPU unavailable !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtHSopXiWCJ5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1521
    },
    "colab_type": "code",
    "id": "JLtzO3dgWICX",
    "outputId": "2dfc6159-7ef4-44d0-80e8-51d01f04c26c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 /150  ;  Training Loss: 0.005745 ; Time consumed: 0m 6s \n",
      "Epoch: 2 /150  ;  Training Loss: 0.005467 ; Time consumed: 0m 6s \n",
      "Epoch: 3 /150  ;  Training Loss: 0.005052 ; Time consumed: 0m 5s \n",
      "Epoch: 4 /150  ;  Training Loss: 0.004803 ; Time consumed: 0m 5s \n",
      "Epoch: 5 /150  ;  Training Loss: 0.004542 ; Time consumed: 0m 6s \n",
      "Epoch: 6 /150  ;  Training Loss: 0.004267 ; Time consumed: 0m 6s \n",
      "Epoch: 7 /150  ;  Training Loss: 0.004031 ; Time consumed: 0m 5s \n",
      "Epoch: 8 /150  ;  Training Loss: 0.003836 ; Time consumed: 0m 5s \n",
      "Epoch: 9 /150  ;  Training Loss: 0.003558 ; Time consumed: 0m 5s \n",
      "Epoch: 10 /150  ;  Training Loss: 0.003334 ; Time consumed: 0m 6s \n",
      "Epoch: 11 /150  ;  Training Loss: 0.003121 ; Time consumed: 0m 5s \n",
      "Epoch: 12 /150  ;  Training Loss: 0.002992 ; Time consumed: 0m 7s \n",
      "Epoch: 13 /150  ;  Training Loss: 0.002792 ; Time consumed: 0m 6s \n",
      "Epoch: 14 /150  ;  Training Loss: 0.002658 ; Time consumed: 0m 5s \n",
      "Epoch: 15 /150  ;  Training Loss: 0.002484 ; Time consumed: 0m 6s \n",
      "Epoch: 16 /150  ;  Training Loss: 0.002314 ; Time consumed: 0m 6s \n",
      "Epoch: 17 /150  ;  Training Loss: 0.002243 ; Time consumed: 0m 6s \n",
      "Epoch: 18 /150  ;  Training Loss: 0.002144 ; Time consumed: 0m 6s \n",
      "Epoch: 19 /150  ;  Training Loss: 0.001926 ; Time consumed: 0m 6s \n",
      "Epoch: 20 /150  ;  Training Loss: 0.001859 ; Time consumed: 0m 6s \n",
      "Epoch: 21 /150  ;  Training Loss: 0.001681 ; Time consumed: 0m 6s \n",
      "Epoch: 22 /150  ;  Training Loss: 0.001640 ; Time consumed: 0m 6s \n",
      "Epoch: 23 /150  ;  Training Loss: 0.001455 ; Time consumed: 0m 6s \n",
      "Epoch: 24 /150  ;  Training Loss: 0.001387 ; Time consumed: 0m 6s \n",
      "Epoch: 25 /150  ;  Training Loss: 0.001332 ; Time consumed: 0m 6s \n",
      "Epoch: 26 /150  ;  Training Loss: 0.001200 ; Time consumed: 0m 5s \n",
      "Epoch: 27 /150  ;  Training Loss: 0.001178 ; Time consumed: 0m 5s \n",
      "Epoch: 28 /150  ;  Training Loss: 0.001060 ; Time consumed: 0m 5s \n",
      "Epoch: 29 /150  ;  Training Loss: 0.001020 ; Time consumed: 0m 6s \n",
      "Epoch: 30 /150  ;  Training Loss: 0.000939 ; Time consumed: 0m 6s \n",
      "Epoch: 31 /150  ;  Training Loss: 0.000886 ; Time consumed: 0m 7s \n",
      "Epoch: 32 /150  ;  Training Loss: 0.000827 ; Time consumed: 0m 5s \n",
      "Epoch: 33 /150  ;  Training Loss: 0.000727 ; Time consumed: 0m 5s \n",
      "Epoch: 34 /150  ;  Training Loss: 0.000730 ; Time consumed: 0m 5s \n",
      "Epoch: 35 /150  ;  Training Loss: 0.000671 ; Time consumed: 0m 5s \n",
      "Epoch: 36 /150  ;  Training Loss: 0.000611 ; Time consumed: 0m 5s \n",
      "Epoch: 37 /150  ;  Training Loss: 0.000546 ; Time consumed: 0m 5s \n",
      "Epoch: 38 /150  ;  Training Loss: 0.000524 ; Time consumed: 0m 5s \n",
      "Epoch: 39 /150  ;  Training Loss: 0.000545 ; Time consumed: 0m 6s \n",
      "Epoch: 40 /150  ;  Training Loss: 0.000463 ; Time consumed: 0m 6s \n",
      "Epoch: 41 /150  ;  Training Loss: 0.000400 ; Time consumed: 0m 6s \n",
      "Epoch: 42 /150  ;  Training Loss: 0.000351 ; Time consumed: 0m 6s \n",
      "Epoch: 43 /150  ;  Training Loss: 0.000372 ; Time consumed: 0m 6s \n",
      "Epoch: 44 /150  ;  Training Loss: 0.000393 ; Time consumed: 0m 6s \n",
      "Epoch: 45 /150  ;  Training Loss: 0.000364 ; Time consumed: 0m 6s \n",
      "Epoch: 46 /150  ;  Training Loss: 0.000279 ; Time consumed: 0m 5s \n",
      "Epoch: 47 /150  ;  Training Loss: 0.000263 ; Time consumed: 0m 6s \n",
      "Epoch: 48 /150  ;  Training Loss: 0.000251 ; Time consumed: 0m 6s \n",
      "Epoch: 49 /150  ;  Training Loss: 0.000222 ; Time consumed: 0m 6s \n",
      "Epoch: 50 /150  ;  Training Loss: 0.000195 ; Time consumed: 0m 6s \n",
      "Epoch: 51 /150  ;  Training Loss: 0.000193 ; Time consumed: 0m 6s \n",
      "Epoch: 52 /150  ;  Training Loss: 0.000198 ; Time consumed: 0m 5s \n",
      "Epoch: 53 /150  ;  Training Loss: 0.000176 ; Time consumed: 0m 6s \n",
      "Epoch: 54 /150  ;  Training Loss: 0.000149 ; Time consumed: 0m 5s \n",
      "Epoch: 55 /150  ;  Training Loss: 0.000143 ; Time consumed: 0m 6s \n",
      "Epoch: 56 /150  ;  Training Loss: 0.000132 ; Time consumed: 0m 6s \n",
      "Epoch: 57 /150  ;  Training Loss: 0.000117 ; Time consumed: 0m 6s \n",
      "Epoch: 58 /150  ;  Training Loss: 0.000113 ; Time consumed: 0m 6s \n",
      "Epoch: 59 /150  ;  Training Loss: 0.000297 ; Time consumed: 0m 6s \n",
      "Epoch: 60 /150  ;  Training Loss: 0.000204 ; Time consumed: 0m 6s \n",
      "Epoch: 61 /150  ;  Training Loss: 0.000094 ; Time consumed: 0m 6s \n",
      "Epoch: 62 /150  ;  Training Loss: 0.000077 ; Time consumed: 0m 6s \n",
      "Epoch: 63 /150  ;  Training Loss: 0.000073 ; Time consumed: 0m 7s \n",
      "Epoch: 64 /150  ;  Training Loss: 0.000065 ; Time consumed: 0m 6s \n",
      "Epoch: 65 /150  ;  Training Loss: 0.000061 ; Time consumed: 0m 6s \n",
      "Epoch: 66 /150  ;  Training Loss: 0.000077 ; Time consumed: 0m 5s \n",
      "Epoch: 67 /150  ;  Training Loss: 0.000058 ; Time consumed: 0m 6s \n",
      "Epoch: 68 /150  ;  Training Loss: 0.000050 ; Time consumed: 0m 6s \n",
      "Epoch: 69 /150  ;  Training Loss: 0.000087 ; Time consumed: 0m 6s \n",
      "Epoch: 70 /150  ;  Training Loss: 0.000441 ; Time consumed: 0m 6s \n",
      "Epoch: 71 /150  ;  Training Loss: 0.000457 ; Time consumed: 0m 6s \n",
      "Epoch: 72 /150  ;  Training Loss: 0.000069 ; Time consumed: 0m 5s \n",
      "Epoch: 73 /150  ;  Training Loss: 0.000052 ; Time consumed: 0m 6s \n",
      "Epoch: 74 /150  ;  Training Loss: 0.000046 ; Time consumed: 0m 6s \n",
      "Epoch: 75 /150  ;  Training Loss: 0.000042 ; Time consumed: 0m 6s \n",
      "Epoch: 76 /150  ;  Training Loss: 0.000039 ; Time consumed: 0m 5s \n",
      "Epoch: 77 /150  ;  Training Loss: 0.000036 ; Time consumed: 0m 6s \n",
      "Epoch: 78 /150  ;  Training Loss: 0.000034 ; Time consumed: 0m 6s \n",
      "Epoch: 79 /150  ;  Training Loss: 0.000033 ; Time consumed: 0m 6s \n",
      "Epoch: 80 /150  ;  Training Loss: 0.000031 ; Time consumed: 0m 5s \n",
      "Epoch: 81 /150  ;  Training Loss: 0.000029 ; Time consumed: 0m 6s \n",
      "Epoch: 82 /150  ;  Training Loss: 0.000028 ; Time consumed: 0m 5s \n",
      "Epoch: 83 /150  ;  Training Loss: 0.000027 ; Time consumed: 0m 6s \n",
      "Epoch: 84 /150  ;  Training Loss: 0.000025 ; Time consumed: 0m 5s \n",
      "Epoch: 85 /150  ;  Training Loss: 0.000024 ; Time consumed: 0m 6s \n",
      "Epoch: 86 /150  ;  Training Loss: 0.000024 ; Time consumed: 0m 5s \n",
      "Epoch: 87 /150  ;  Training Loss: 0.000022 ; Time consumed: 0m 6s \n",
      "Epoch: 88 /150  ;  Training Loss: 0.000022 ; Time consumed: 0m 6s \n",
      "Epoch: 89 /150  ;  Training Loss: 0.000020 ; Time consumed: 0m 6s \n",
      "Epoch: 90 /150  ;  Training Loss: 0.000018 ; Time consumed: 0m 7s \n",
      "Epoch: 91 /150  ;  Training Loss: 0.000018 ; Time consumed: 0m 7s \n",
      "Epoch: 92 /150  ;  Training Loss: 0.000017 ; Time consumed: 0m 7s \n",
      "Epoch: 93 /150  ;  Training Loss: 0.000016 ; Time consumed: 0m 6s \n",
      "Epoch: 94 /150  ;  Training Loss: 0.000016 ; Time consumed: 0m 6s \n",
      "Epoch: 95 /150  ;  Training Loss: 0.000015 ; Time consumed: 0m 6s \n",
      "Epoch: 96 /150  ;  Training Loss: 0.000014 ; Time consumed: 0m 6s \n",
      "Epoch: 97 /150  ;  Training Loss: 0.000014 ; Time consumed: 0m 6s \n",
      "Epoch: 98 /150  ;  Training Loss: 0.000829 ; Time consumed: 0m 6s \n",
      "Epoch: 99 /150  ;  Training Loss: 0.000312 ; Time consumed: 0m 6s \n",
      "Epoch: 100 /150  ;  Training Loss: 0.000045 ; Time consumed: 0m 6s \n",
      "Epoch: 101 /150  ;  Training Loss: 0.000030 ; Time consumed: 0m 6s \n",
      "Epoch: 102 /150  ;  Training Loss: 0.000025 ; Time consumed: 0m 6s \n",
      "Epoch: 103 /150  ;  Training Loss: 0.000022 ; Time consumed: 0m 6s \n",
      "Epoch: 104 /150  ;  Training Loss: 0.000020 ; Time consumed: 0m 6s \n",
      "Epoch: 105 /150  ;  Training Loss: 0.000018 ; Time consumed: 0m 6s \n",
      "Epoch: 106 /150  ;  Training Loss: 0.000017 ; Time consumed: 0m 6s \n",
      "Epoch: 107 /150  ;  Training Loss: 0.000016 ; Time consumed: 0m 6s \n",
      "Epoch: 108 /150  ;  Training Loss: 0.000015 ; Time consumed: 0m 6s \n",
      "Epoch: 109 /150  ;  Training Loss: 0.000014 ; Time consumed: 0m 6s \n",
      "Epoch: 110 /150  ;  Training Loss: 0.000013 ; Time consumed: 0m 6s \n",
      "Epoch: 111 /150  ;  Training Loss: 0.000013 ; Time consumed: 0m 6s \n",
      "Epoch: 112 /150  ;  Training Loss: 0.000012 ; Time consumed: 0m 6s \n",
      "Epoch: 113 /150  ;  Training Loss: 0.000012 ; Time consumed: 0m 6s \n",
      "Epoch: 114 /150  ;  Training Loss: 0.000011 ; Time consumed: 0m 6s \n",
      "Epoch: 115 /150  ;  Training Loss: 0.000011 ; Time consumed: 0m 6s \n",
      "Epoch: 116 /150  ;  Training Loss: 0.000010 ; Time consumed: 0m 6s \n",
      "Epoch: 117 /150  ;  Training Loss: 0.000010 ; Time consumed: 0m 6s \n",
      "Epoch: 118 /150  ;  Training Loss: 0.000009 ; Time consumed: 0m 6s \n",
      "Epoch: 119 /150  ;  Training Loss: 0.000009 ; Time consumed: 0m 6s \n",
      "Epoch: 120 /150  ;  Training Loss: 0.000009 ; Time consumed: 0m 6s \n",
      "Epoch: 121 /150  ;  Training Loss: 0.000008 ; Time consumed: 0m 6s \n",
      "Epoch: 122 /150  ;  Training Loss: 0.000008 ; Time consumed: 0m 6s \n",
      "Epoch: 123 /150  ;  Training Loss: 0.000008 ; Time consumed: 0m 6s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 /150  ;  Training Loss: 0.000007 ; Time consumed: 0m 6s \n",
      "Epoch: 125 /150  ;  Training Loss: 0.000007 ; Time consumed: 0m 6s \n",
      "Epoch: 126 /150  ;  Training Loss: 0.000007 ; Time consumed: 0m 6s \n",
      "Epoch: 127 /150  ;  Training Loss: 0.000007 ; Time consumed: 0m 6s \n",
      "Epoch: 128 /150  ;  Training Loss: 0.000006 ; Time consumed: 0m 6s \n",
      "Epoch: 129 /150  ;  Training Loss: 0.000006 ; Time consumed: 0m 6s \n",
      "Epoch: 130 /150  ;  Training Loss: 0.000006 ; Time consumed: 0m 6s \n",
      "Epoch: 131 /150  ;  Training Loss: 0.000006 ; Time consumed: 0m 7s \n",
      "Epoch: 132 /150  ;  Training Loss: 0.000005 ; Time consumed: 0m 7s \n",
      "Epoch: 133 /150  ;  Training Loss: 0.000005 ; Time consumed: 0m 6s \n",
      "Epoch: 134 /150  ;  Training Loss: 0.000005 ; Time consumed: 0m 7s \n",
      "Epoch: 135 /150  ;  Training Loss: 0.000005 ; Time consumed: 0m 7s \n",
      "Epoch: 136 /150  ;  Training Loss: 0.000005 ; Time consumed: 0m 6s \n",
      "Epoch: 137 /150  ;  Training Loss: 0.000004 ; Time consumed: 0m 6s \n",
      "Epoch: 138 /150  ;  Training Loss: 0.000004 ; Time consumed: 0m 6s \n",
      "Epoch: 139 /150  ;  Training Loss: 0.000004 ; Time consumed: 0m 5s \n",
      "Epoch: 140 /150  ;  Training Loss: 0.000004 ; Time consumed: 0m 6s \n",
      "Epoch: 141 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 142 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 143 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 144 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 145 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 146 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 147 /150  ;  Training Loss: 0.000003 ; Time consumed: 0m 6s \n",
      "Epoch: 148 /150  ;  Training Loss: 0.000002 ; Time consumed: 0m 6s \n",
      "Epoch: 149 /150  ;  Training Loss: 0.000002 ; Time consumed: 0m 6s \n",
      "Epoch: 150 /150  ;  Training Loss: 0.000002 ; Time consumed: 0m 6s \n",
      "Training finished in 14m 35s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalEpochs = 150\n",
    "trainLossList = []\n",
    "startTime = time.time()\n",
    "for epoch in range(totalEpochs):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0    \n",
    "    net.train(True) # For training\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), \\\n",
    "                Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)  \n",
    "       \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Feed-forward input data through the network        \n",
    "        outputs = net(inputs)        \n",
    "        # Compute loss/error\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.data \n",
    "    avgTrainLoss = runningLoss/8000.0\n",
    "    trainLossList.append(avgTrainLoss)\n",
    "        \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLossList,'r-',label='train')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Training loss')       \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Epoch: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,totalEpochs,avgTrainLoss,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-startTime\n",
    "print('Training finished in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting test labels and saving into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "rDr6jrcsNZms",
    "outputId": "420837bf-1134-4a43-d9d7-ab10bf51077e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansha/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    inputs = Variable(testImages.cuda())  \n",
    "else:\n",
    "    inputs = Variable(testImages)\n",
    "\n",
    "outputs = net(inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "finalPred = predicted.cpu().numpy()\n",
    "\n",
    "# Replacing class label 1 with 6\n",
    "for i in range(2000):\n",
    "    if finalPred[i] == 1:\n",
    "        finalPred[i] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmem06IS2eHe"
   },
   "outputs": [],
   "source": [
    "# Saving predictions into a file\n",
    "x = np.arange(0, 2000, 1)\n",
    "x.astype(int)\n",
    "final = np.asarray((x,finalPred),dtype = int)\n",
    "np.savetxt(\"Testlabel.csv\",final.T,fmt='%d' ,delimiter=',', header='image,pred',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TaskCV.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
